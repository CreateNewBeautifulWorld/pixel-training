# 🎯 网络架构探索 - 完整工作流程

## 📋 两阶段策略总结

### ✅ 你现在拥有的工具

1. **explore_architecture.py** 
   - 阶段1：探索最优结构
   - 使用FP16训练
   - 输出：回归任务（单float）
   - 自动测试多种配置

2. **train_configurable.py**
   - 阶段2：用最优结构训练
   - 可选FP16或Uint8
   - 生成训练曲线

3. **inference_uint8.cpp**
   - 阶段3：C++推理部署
   - Uint8量化版本

---

## 🚀 完整工作流程

### 第1步：探索阶段 (找最优结构)

```bash
# 快速探索（推荐先跑这个）
python explore_architecture.py \
    --pixels 4 8 16 \
    --layers 0 1 2 \
    --neurons 8 16 \
    --epochs 50
```

**输出**:
```
exploration_results/
├── exploration_results_YYYYMMDD_HHMMSS.json
├── exploration_analysis.png
└── comparison_table.txt
```

---

### 第2步：查看结果

```bash
# 查看排名
cat exploration_results/comparison_table.txt | head -15

# 查看可视化
open exploration_results/exploration_analysis.png  # Mac
# 或 eog exploration_results/exploration_analysis.png  # Linux
```

**示例输出**:
```
排名   网络结构              像素  层数  神经元  参数量  验证损失
1      24 -> 8 -> 8 -> 1    8     2     8       281     0.019329
2      24 -> 16 -> 16 -> 1  8     2     16      689     0.026090
3      12 -> 8 -> 1         4     1     8       113     0.027257
```

**解读**:
- 🏆 最优配置：8像素 + 2层 + 8神经元
- 参数量：281 bytes（很小！）
- 验证损失：0.019（很好！）

---

### 第3步：用最优配置精细训练

假设探索发现最优是 `24 -> 8 -> 8 -> 1` (8像素，2层隐藏层，各8神经元):

```bash
# 用可配置脚本训练更多轮
python train_configurable.py \
    --num_pixels 8 \
    --hidden_layers 8 8 \
    --num_classes 1 \
    --epochs 200 \
    --learning_rate 0.01
```

注意：
- `--num_classes 1` 表示回归任务（单输出）
- 训练更多轮（200 vs 50）获得更好结果

---

### 第4步：量化到Uint8（如果需要）

探索用的是FP16，部署需要Uint8：

```python
# 修改train_configurable.py，添加Uint8量化
# 或者单独写一个量化脚本
```

---

### 第5步：部署

```bash
# 编译C++推理
make

# 运行
./inference_uint8
```

---

## 📊 实际示例结果分析

我刚运行了一个小规模探索：
- 像素：4, 8
- 层数：0, 1, 2
- 神经元：8, 16
- 总共12个配置

### 关键发现

1. **0层（线性）表现差**
   - `12 -> 1` (4像素): 损失 0.0746
   - `24 -> 1` (8像素): 损失 0.0641
   - 结论：线性模型不够

2. **1层比2层简单但损失稍高**
   - 1层：`24 -> 8 -> 1`: 损失 0.0623
   - 2层：`24 -> 8 -> 8 -> 1`: 损失 0.0193
   - 结论：2层明显更好

3. **8像素比4像素好**
   - 4像素最优：`12 -> 8 -> 1`: 损失 0.0273
   - 8像素最优：`24 -> 8 -> 8 -> 1`: 损失 0.0193
   - 结论：更多输入带来更好性能

4. **参数量 vs 性能**
   - 281参数(8像素+2层+8神经元): 0.0193
   - 689参数(8像素+2层+16神经元): 0.0261
   - 结论：16神经元反而更差（过拟合）

### 可视化图表解读

**图1 (左上): 参数量 vs 损失**
- 散点分布
- 找"拐点"：281参数已经很好
- 更多参数不一定更好

**图2 (右上): 层数 vs 损失**
- 0层：高损失（0.06-0.11）
- 1层：中等（0.04-0.06）
- 2层：低损失（0.02-0.03）
- 结论：2层最优

**图3 (左下): 输入维度 vs 损失**
- 12输入(4像素)：损失较高
- 24输入(8像素)：损失较低
- 结论：8像素是sweet spot

**图4 (右下): Top 5训练曲线**
- 蓝线 `24->8->8->1`: 收敛最快最好
- 其他曲线都在其上方
- 所有曲线都平滑下降（训练稳定）

---

## 💡 如何选择最优配置

### 方法1: 纯粹看损失
```
选最小验证损失的配置
→ 示例: 24 -> 8 -> 8 -> 1 (损失0.0193)
```

### 方法2: 考虑资源约束
```
如果硬件只有200 bytes:
→ 选 12 -> 8 -> 1 (113参数, 损失0.0273)

如果硬件有500 bytes:
→ 选 24 -> 8 -> 8 -> 1 (281参数, 损失0.0193)
```

### 方法3: 性价比
```
损失/参数量 比值:
24->8->8->1:   0.0193 / 281 = 0.000069  ← 最佳性价比
24->16->16->1: 0.0261 / 689 = 0.000038  ← 性价比差
```

---

## 🎯 针对你的需求

你提到的探索范围：
- **像素数**: 1-64
- **隐藏层数**: 0-5
- **神经元数**: 1-32
- **输出**: 1个bool (float)

### 完整探索命令

```bash
# 警告：这会跑很久！
python explore_architecture.py \
    --pixels 1 2 4 8 16 32 64 \
    --layers 0 1 2 3 4 5 \
    --neurons 1 2 4 8 16 32 \
    --epochs 100 \
    --samples 2000

# 预计：7 × 6 × 6 = 252个配置
# 时间：6-10小时
```

### 推荐分阶段探索

**阶段A: 粗搜索** (30分钟)
```bash
python explore_architecture.py \
    --pixels 1 4 16 64 \
    --layers 0 1 2 3 \
    --neurons 4 16 32 \
    --epochs 50
```
→ 找到大致范围（例如：16像素+2层+16神经元）

**阶段B: 细搜索** (1小时)
```bash
python explore_architecture.py \
    --pixels 12 16 20 \
    --layers 1 2 3 \
    --neurons 12 16 20 \
    --epochs 100
```
→ 找到精确最优

**阶段C: 验证** (2小时)
```bash
# 用最优配置多训练几次确认
python train_configurable.py \
    --num_pixels 16 \
    --hidden_layers 16 16 \
    --epochs 300
```

---

## 📈 预期发现

基于经验，你可能会发现：

### 输入规模
```
1-2像素   → 信息不足，损失 > 0.08
4-8像素   → 性价比高，损失 0.02-0.05
16-32像素 → 性能好，损失 < 0.02
64像素    → 边际收益小
```

### 隐藏层数
```
0层 → 只能线性，损失 > 0.06
1层 → 简单非线性，损失 0.03-0.05
2层 → 大部分任务够用，损失 0.01-0.03
3层+ → 可能过拟合，除非数据多
```

### 神经元数
```
1-4   → 太简单
8-16  → sweet spot
32+   → 除非数据量大，否则过拟合
```

### 最优配置猜测
```
可能的最优组合：
- 16像素 + 2层 + 16神经元 ≈ 850参数
- 或 8像素 + 2层 + 12神经元 ≈ 350参数
```

---

## 🔧 调试和优化

### 如果所有配置损失都很高 (> 0.05)

**可能原因**:
1. 训练轮数不够 → 增加 `--epochs 200`
2. 数据量太少 → 增加 `--samples 5000`
3. 学习率不对 → 修改代码中的learning_rate
4. 任务太难 → 检查数据生成函数

**解决**:
```bash
python explore_architecture.py \
    --epochs 200 \
    --samples 5000
```

---

### 如果训练曲线震荡

**可能原因**: 学习率太大

**解决**: 修改 `explore_architecture.py` 中的：
```python
model.train(..., learning_rate=0.005)  # 从0.01改为0.005
```

---

### 如果想加快速度

```bash
# 减少配置数
python explore_architecture.py \
    --pixels 8 16 \
    --layers 1 2 \
    --neurons 8 16 \
    --epochs 30  # 减少轮数
```

---

## 📝 checklist

### 开始探索前
- [ ] 确认Python环境有numpy, matplotlib
- [ ] 理解你的任务（回归 or 分类？）
- [ ] 确定资源约束（多少参数可接受？）
- [ ] 估算时间（配置数 × 每配置时间）

### 探索过程中
- [ ] 监控第一个配置是否正常
- [ ] 确认输出文件正在生成
- [ ] 如果太慢，考虑减少配置

### 探索完成后
- [ ] 查看对比表排名
- [ ] 查看可视化图表
- [ ] 记录最优配置
- [ ] 用最优配置重新训练验证

### 部署前
- [ ] 量化到Uint8
- [ ] 测试C++推理
- [ ] 验证精度损失可接受
- [ ] 综合到RTL设计

---

## 🎉 总结

**你现在有**:
1. ✅ 探索脚本 (`explore_architecture.py`)
2. ✅ 训练脚本 (`train_configurable.py`)
3. ✅ 推理引擎 (`inference_uint8.cpp`)
4. ✅ RTL参考 (`uint8_nn_rtl.v`)
5. ✅ 完整文档

**下一步**:
1. 运行小规模探索熟悉流程
2. 运行完整探索找最优
3. 用最优配置训练部署
4. 享受你的最优网络！

开始探索吧！🚀
